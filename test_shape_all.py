#!/usr/bin/env python3
"""
ì „ì²´ shape ì˜¤ë¥˜ í…ŒìŠ¤íŠ¸: SSM, FlowMatching, VoiceConversionModel
"""
import torch

try:
    from ssm import S6SSMEncoder
except ImportError as e:
    print(f"âŒ SSM import ì‹¤íŒ¨: {e}")
    S6SSMEncoder = None

try:
    from flow_matching import FlowMatching
except ImportError as e:
    print(f"âŒ FlowMatching import ì‹¤íŒ¨: {e}")
    FlowMatching = None

try:
    from model import VoiceConversionModel
except ImportError as e:
    print(f"âŒ VoiceConversionModel import ì‹¤íŒ¨: {e}")
    VoiceConversionModel = None


def test_ssm_encoder():
    if S6SSMEncoder is None:
        print("âš ï¸ S6SSMEncoder ì—†ìŒ, í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
        return

    print("\n[SSM] S6SSMEncoder shape test")
    B, T, D = 2, 50, 768
    x = torch.randn(B, T, D)
    model = S6SSMEncoder(d_model=D, n_layers=3)
    y = model(x)
    print(f"  ì…ë ¥: {x.shape} -> ì¶œë ¥: {y.shape}")
    assert y.shape == (B, T, D)
    print("  âœ… SSM shape OK")


def test_flow_matching():
    if FlowMatching is None:
        print("âš ï¸ FlowMatching ì—†ìŒ, í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
        return

    print("\n[FlowMatching] shape test")
    B, waveform_length, cond_dim = 2, 16384, 768
    x1 = torch.randn(B, waveform_length)
    condition = torch.randn(B, cond_dim)
    model = FlowMatching(dim=waveform_length, condition_dim=cond_dim, steps=8)
    
    try:
        # loss
        loss = model.compute_loss(x1, condition)
        print(f"  Loss: {loss.item():.4f}")
    except Exception as e:
        print(f"âŒ FlowMatching loss ê³„ì‚° ì‹¤íŒ¨: {e}")
        return

    try:
        # sample
        out = model.sample(condition, num_steps=4, method='fast_inverse')
        print(f"  ìƒ˜í”Œ shape: {out.shape}")
        assert out.shape == (B, waveform_length)
    except Exception as e:
        print(f"âŒ FlowMatching ìƒ˜í”Œë§ ì‹¤íŒ¨: {e}")
        return

    print("  âœ… FlowMatching shape OK")


def test_voice_conversion_model():
    if VoiceConversionModel is None:
        print("âš ï¸ VoiceConversionModel ì—†ìŒ, í…ŒìŠ¤íŠ¸ ìŠ¤í‚µ")
        return

    print("\n[VoiceConversionModel] shape test")
    B, L, n_speakers = 2, 16384, 8
    source_waveform = torch.randn(B, L)
    target_speaker_id = torch.randint(0, n_speakers, (B,))
    model = VoiceConversionModel(d_model=768, n_speakers=n_speakers, waveform_length=L, use_retrieval=False)
    
    try:
        with torch.no_grad():
            result = model(source_waveform, target_speaker_id, target_waveform=source_waveform, training=True)
        print(f"  ê²°ê³¼ keys: {list(result.keys())}")
        print(f"  flow_loss: {result['flow_loss'].item():.4f}")
    except Exception as e:
        print(f"âŒ VoiceConversionModel ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return

    print("  âœ… VoiceConversionModel shape OK")


if __name__ == "__main__":
    print("ğŸš€ ì „ì²´ shape í…ŒìŠ¤íŠ¸ ì‹œì‘")
    test_ssm_encoder()
    test_flow_matching()
    test_voice_conversion_model()
