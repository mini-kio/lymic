import torch
import torch.nn as nn
import torch.nn.functional as F
import math

class RectifiedFlow(nn.Module):
    """
    ğŸ”¥ Rectified Flow for Efficient Waveform Generation
    - ì§ì„ ì  ê²½ë¡œë¡œ ë” íš¨ìœ¨ì ì¸ í•™ìŠµ
    - ì ì€ ë‹¨ê³„ë¡œë„ ê³ í’ˆì§ˆ ìƒì„±
    - FP16 ìµœì í™” ì ìš©
    """
    def __init__(self, dim=16384, condition_dim=768, steps=20, hidden_dim=512):
        super().__init__()
        self.dim = dim
        self.condition_dim = condition_dim
        self.steps = steps
        
        # ğŸ”¥ ê²½ëŸ‰í™”ëœ ë²¡í„° í•„ë“œ ë„¤íŠ¸ì›Œí¬
        self.vector_field = RectifiedVectorField(
            dim=dim,
            condition_dim=condition_dim,
            hidden_dim=hidden_dim
        )
        
        # ğŸš€ ìµœì í™” ì„¤ì •
        self._compiled = False
        
    def compile_model(self):
        """ë²¡í„° í•„ë“œ ì»´íŒŒì¼"""
        if not self._compiled:
            try:
                self.vector_field = torch.compile(self.vector_field, mode='max-autotune')
                self._compiled = True
                print("ğŸš€ RectifiedFlow compiled")
            except Exception as e:
                print(f"âš ï¸ RectifiedFlow compilation failed: {e}")
    
    def compute_loss(self, x1, condition):
        """
        ğŸ”¥ Rectified Flow ì†ì‹¤ ê³„ì‚°
        ë” ì§ì„ ì ì¸ ê²½ë¡œë¡œ í•™ìŠµ íš¨ìœ¨ì„± í–¥ìƒ
        
        Args:
            x1: (B, dim) íƒ€ê²Ÿ íŒŒí˜•
            condition: (B, condition_dim) ì¡°ê±´
        """
        B = x1.size(0)
        device = x1.device
        
        # ì‹œê°„ ìƒ˜í”Œë§ (ê· ë“± ë¶„í¬)
        t = torch.rand(B, device=device, dtype=x1.dtype)
        
        # ë…¸ì´ì¦ˆ ìƒ˜í”Œë§ (ê°€ìš°ì‹œì•ˆ)
        x0 = torch.randn_like(x1)
        
        # ğŸ”¥ Rectified Flow: ì§ì„ ì  ë³´ê°„
        t_expanded = t.view(B, 1)
        x_t = (1 - t_expanded) * x0 + t_expanded * x1
        
        # ğŸ”¥ íƒ€ê²Ÿ ì†ë„ (ì§ì„  ê²½ë¡œ)
        target_velocity = x1 - x0
        
        # ğŸ”¥ ì†ë„ ì˜ˆì¸¡
        predicted_velocity = self.vector_field(x_t, t, condition)
        
        # MSE ì†ì‹¤
        loss = F.mse_loss(predicted_velocity, target_velocity)
        
        return loss
    
    @torch.amp.autocast('cuda')
    def sample(self, condition, num_steps=None, x0=None, method='fast_rectified'):
        """
        ğŸš€ ìµœì í™”ëœ ìƒ˜í”Œë§ - ì—¬ëŸ¬ ë¹ ë¥¸ ë°©ë²• ì§€ì›
        """
        if num_steps is None:
            num_steps = max(4, self.steps // 5)  # ê¸°ë³¸ì ìœ¼ë¡œ ë§¤ìš° ë¹ ë¥´ê²Œ
        
        B = condition.size(0)
        device = condition.device
        
        if x0 is None:
            x0 = torch.randn(B, self.dim, device=device, dtype=condition.dtype)
        
        # ë°©ë²•ì— ë”°ë¥¸ ë¶„ê¸°
        if method == 'fast_rectified':
            return self._sample_fast_rectified(condition, x0, num_steps)
        elif method == 'heun':
            return self._sample_heun(condition, x0, num_steps)
        elif method == 'rk4':
            return self._sample_rk4(condition, x0, num_steps)
        else:  # euler
            return self._sample_euler(condition, x0, num_steps)
    
    def _sample_fast_rectified(self, condition, x0, num_steps):
        """
        ğŸš€ Ultra-fast Rectified Flow ìƒ˜í”Œë§
        - ì ì‘ì  ë‹¨ê³„ í¬ê¸°
        - ê³ ì°¨ ì •í™•ë„
        """
        # ì ì‘ì  ë‹¨ê³„ ìŠ¤ì¼€ì¤„
        step_schedule = self._get_optimal_schedule(num_steps)
        
        x = x0
        t = 0.0
        
        for i, dt in enumerate(step_schedule):
            t_tensor = torch.full((x.size(0),), t, device=x.device, dtype=x.dtype)
            
            if i == 0:
                # ì²« ë‹¨ê³„: Euler
                v = self.vector_field(x, t_tensor, condition)
                x = x + dt * v
            elif i >= len(step_schedule) - 2:
                # ë§ˆì§€ë§‰ 2ë‹¨ê³„: RK4ë¡œ ì •í™•ë„ í–¥ìƒ
                x = self._rk4_step(x, t, dt, condition)
            else:
                # ì¤‘ê°„ ë‹¨ê³„: Heun's method
                v1 = self.vector_field(x, t_tensor, condition)
                x_pred = x + dt * v1
                
                t_next = torch.full((x.size(0),), t + dt, device=x.device, dtype=x.dtype)
                v2 = self.vector_field(x_pred, t_next, condition)
                
                x = x + dt * 0.5 * (v1 + v2)
            
            t += dt
        
        return x
    
    def _get_optimal_schedule(self, num_steps):
        """ìµœì í™”ëœ ë‹¨ê³„ ìŠ¤ì¼€ì¤„"""
        # Rectified Flowì— ìµœì í™”ëœ ìŠ¤ì¼€ì¤„
        # ì´ˆê¸°ì—ëŠ” í° ë‹¨ê³„, í›„ë°˜ì—ëŠ” ì‘ì€ ë‹¨ê³„
        
        if num_steps <= 1:
            return [1.0]
        
        # ì§€ìˆ˜ì  ê°ì†Œ + ì„ í˜• ì¡°í•©
        alpha = 0.2  # ê°ì†Œìœ¨
        steps = []
        
        for i in range(num_steps):
            # ë¹„ì„ í˜• ìŠ¤ì¼€ì¤„ë§
            progress = i / (num_steps - 1)
            
            # ì´ˆê¸°ì—ëŠ” í° ë‹¨ê³„, í›„ë°˜ì—ëŠ” ì„¸ë°€í•œ ë‹¨ê³„
            weight = math.exp(-alpha * progress)
            
            steps.append(weight)
        
        # ì •ê·œí™”í•˜ì—¬ ì´í•©ì´ 1ì´ ë˜ë„ë¡
        total = sum(steps)
        steps = [s / total for s in steps]
        
        return steps
    
    def _sample_euler(self, condition, x0, num_steps):
        """í‘œì¤€ Euler ì ë¶„"""
        dt = 1.0 / num_steps
        x = x0
        
        for i in range(num_steps):
            t = torch.full((x.size(0),), i * dt, device=x.device, dtype=x.dtype)
            v = self.vector_field(x, t, condition)
            x = x + dt * v
        
        return x
    
    def _sample_heun(self, condition, x0, num_steps):
        """Heun's method (RK2)"""
        dt = 1.0 / num_steps
        x = x0
        
        for i in range(num_steps):
            t = torch.full((x.size(0),), i * dt, device=x.device, dtype=x.dtype)
            
            # Heun's method
            v1 = self.vector_field(x, t, condition)
            x_pred = x + dt * v1
            
            t_next = torch.full((x.size(0),), (i + 1) * dt, device=x.device, dtype=x.dtype)
            v2 = self.vector_field(x_pred, t_next, condition)
            
            x = x + dt * 0.5 * (v1 + v2)
        
        return x
    
    def _sample_rk4(self, condition, x0, num_steps):
        """4ì°¨ Runge-Kutta"""
        dt = 1.0 / num_steps
        x = x0
        
        for i in range(num_steps):
            t = i * dt
            x = self._rk4_step(x, t, dt, condition)
        
        return x
    
    def _rk4_step(self, x, t, dt, condition):
        """RK4 ë‹¨ì¼ ë‹¨ê³„"""
        t_tensor = torch.full((x.size(0),), t, device=x.device, dtype=x.dtype)
        k1 = self.vector_field(x, t_tensor, condition)
        
        t_mid1 = torch.full((x.size(0),), t + dt/2, device=x.device, dtype=x.dtype)
        k2 = self.vector_field(x + dt/2 * k1, t_mid1, condition)
        
        k3 = self.vector_field(x + dt/2 * k2, t_mid1, condition)
        
        t_end = torch.full((x.size(0),), t + dt, device=x.device, dtype=x.dtype)
        k4 = self.vector_field(x + dt * k3, t_end, condition)
        
        return x + dt/6 * (k1 + 2*k2 + 2*k3 + k4)

class RectifiedVectorField(nn.Module):
    """
    ğŸ”¥ ìµœì í™”ëœ ë²¡í„° í•„ë“œ ë„¤íŠ¸ì›Œí¬
    - FP16 ìµœì í™”
    - ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì„¤ê³„
    - ì»´íŒŒì¼ ìµœì í™” ì ìš©
    """
    def __init__(self, dim=16384, condition_dim=768, hidden_dim=512):
        super().__init__()
        
        self.dim = dim
        self.condition_dim = condition_dim
        
        # ğŸ”¥ ì‹œê°„ ì„ë² ë”© (ìµœì í™”)
        self.time_embedding = OptimizedTimeEmbedding(hidden_dim)
        
        # ğŸ”¥ íš¨ìœ¨ì ì¸ íŒŒí˜• í”„ë¡œì ì…˜
        self.waveform_proj = nn.Sequential(
            nn.Linear(dim, hidden_dim),
            nn.SiLU(),
            nn.Dropout(0.05),  # ë‚®ì€ ë“œë¡­ì•„ì›ƒ
            nn.Linear(hidden_dim, hidden_dim // 4)
        )
        
        # ì¡°ê±´ í”„ë¡œì ì…˜
        self.condition_proj = nn.Linear(condition_dim, hidden_dim // 4)
        
        # ğŸ”¥ ìµœì í™”ëœ ë©”ì¸ ë„¤íŠ¸ì›Œí¬
        self.net = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Dropout(0.05),
            nn.Linear(hidden_dim, hidden_dim),
            nn.SiLU(),
            nn.Linear(hidden_dim, dim)  # ì¶œë ¥: íŒŒí˜• ì†ë„
        )
        
        # ğŸ”¥ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ìµœì í™”
        self._initialize_weights()
        
    def _initialize_weights(self):
        """íš¨ìœ¨ì ì¸ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”"""
        for module in self.modules():
            if isinstance(module, nn.Linear):
                # He ì´ˆê¸°í™” (SiLUì— ìµœì í™”)
                nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')
                if module.bias is not None:
                    nn.init.zeros_(module.bias)
    
    @torch.amp.autocast('cuda')
    def forward(self, x, t, condition):
        """
        ìµœì í™”ëœ ìˆœì „íŒŒ
        Args:
            x: (B, dim) ì…ë ¥ íŒŒí˜•
            t: (B,) ì‹œê°„
            condition: (B, condition_dim) ì¡°ê±´
        """
        # ì„ë² ë”©ë“¤
        x_emb = self.waveform_proj(x)  # (B, hidden_dim//4)
        t_emb = self.time_embedding(t)  # (B, hidden_dim//2)
        c_emb = self.condition_proj(condition)  # (B, hidden_dim//4)
        
        # ì—°ê²° - ì°¨ì› ë§ì¶¤
        h = torch.cat([x_emb, t_emb, c_emb], dim=-1)  # (B, hidden_dim)
        
        # ì†ë„ ì˜ˆì¸¡
        velocity = self.net(h)
        
        return velocity

class OptimizedTimeEmbedding(nn.Module):
    """ìµœì í™”ëœ ì‹œê°„ ì„ë² ë”©"""
    def __init__(self, dim):
        super().__init__()
        self.dim = dim
        
        # ì‚¬ì „ ê³„ì‚°ëœ ìƒìˆ˜
        half_dim = dim // 4  # hidden_dimì˜ 1/2ë¥¼ ì°¨ì§€í•˜ë„ë¡ ìˆ˜ì •
        emb = math.log(10000) / (half_dim - 1) if half_dim > 1 else 0
        self.register_buffer('emb_scale', torch.exp(torch.arange(half_dim) * -emb))
        self.proj = nn.Linear(half_dim * 2, dim // 2)  # ìµœì¢… ì¶œë ¥ ì°¨ì› ë§ì¶¤
        
    @torch.amp.autocast('cuda')
    def forward(self, t):
        """
        ë¹ ë¥¸ ì‹œê°„ ì„ë² ë”©
        Args:
            t: (N,) ì‹œê°„ ê°’ [0, 1]
        """
        if len(self.emb_scale) == 0:
            # half_dimì´ 0ì¸ ê²½ìš° ì²˜ë¦¬
            return torch.zeros(t.size(0), self.dim // 2, device=t.device, dtype=t.dtype)
            
        emb = t.unsqueeze(-1) * self.emb_scale.unsqueeze(0)
        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)
        
        # í”„ë¡œì ì…˜ì„ í†µí•´ ì°¨ì› ë§ì¶¤
        emb = self.proj(emb)
            
        return emb

# ğŸ”¥ ì¶”ê°€ ìµœì í™” ìœ í‹¸ë¦¬í‹°ë“¤
class FlowScheduler:
    """ë™ì  ìŠ¤ì¼€ì¤„ë§ìœ¼ë¡œ ì¶”ë¡  ì†ë„ ìµœì í™”"""
    
    @staticmethod
    def get_adaptive_steps(quality_target='fast'):
        """í’ˆì§ˆ ëª©í‘œì— ë”°ë¥¸ ì ì‘ì  ë‹¨ê³„ ìˆ˜"""
        schedules = {
            'ultra_fast': 3,
            'fast': 6,
            'balanced': 12,
            'high_quality': 20,
            'best': 30
        }
        return schedules.get(quality_target, 6)
    
    @staticmethod
    def get_progressive_schedule(max_steps, current_epoch, total_epochs):
        """í›ˆë ¨ ì¤‘ ì ì§„ì  ë‹¨ê³„ ì¦ê°€"""
        # ì´ˆê¸°ì—ëŠ” ì ì€ ë‹¨ê³„, í›„ë°˜ì—ëŠ” ë§ì€ ë‹¨ê³„
        progress = current_epoch / total_epochs
        min_steps = max(2, max_steps // 10)
        steps = int(min_steps + (max_steps - min_steps) * progress)
        return min(steps, max_steps)

# ğŸš€ ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•œ ì»´íŒŒì¼ ë˜í¼
def compile_rectified_flow(model):
    """RectifiedFlow ëª¨ë¸ ì»´íŒŒì¼"""
    try:
        if hasattr(torch, 'compile'):
            model.vector_field = torch.compile(
                model.vector_field, 
                mode='max-autotune',
                dynamic=True
            )
            print("ğŸš€ RectifiedFlow vector field compiled")
        else:
            print("âš ï¸ torch.compile not available")
    except Exception as e:
        print(f"âš ï¸ Compilation failed: {e}")
    
    return model