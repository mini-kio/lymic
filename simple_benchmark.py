"""
ê°„ë‹¨í•œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
"""
import torch
from flow_matching import RectifiedFlow
from ssm import OptimizedS6Block, FastS6Block

def simple_benchmark():
    """ê°„ë‹¨í•œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("ğŸš€ Simple Performance Check")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device: {device}")
    
    # Flow Matching í…ŒìŠ¤íŠ¸
    print("\nğŸ”¥ Flow Matching Test:")
    flow = RectifiedFlow(dim=1024, condition_dim=768, hidden_dim=256).to(device)
    condition = torch.randn(2, 768, device=device)
    x1 = torch.randn(2, 1024, device=device)
    
    import time
    start = time.time()
    loss = flow.compute_loss(x1, condition)
    print(f"  Loss computation: {(time.time() - start)*1000:.2f}ms")
    
    start = time.time()
    with torch.no_grad():
        samples = flow.sample(condition, num_steps=4)
    print(f"  Sampling: {(time.time() - start)*1000:.2f}ms")
    
    # SSM í…ŒìŠ¤íŠ¸
    print("\nğŸš€ SSM Test:")
    s6_block = OptimizedS6Block(d_model=256, d_state=32).to(device)
    fast_block = FastS6Block(d_model=256, d_state=16).to(device)
    
    x = torch.randn(2, 100, 256, device=device)
    
    start = time.time()
    out1 = s6_block(x)
    print(f"  OptimizedS6: {(time.time() - start)*1000:.2f}ms")
    
    start = time.time()
    out2 = fast_block(x)
    print(f"  FastS6: {(time.time() - start)*1000:.2f}ms")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
    if torch.cuda.is_available():
        memory_mb = torch.cuda.memory_allocated() / 1024 / 1024
        print(f"\nğŸ’¾ Memory usage: {memory_mb:.2f}MB")
    
    print("\nâœ… Simple benchmark completed!")

if __name__ == "__main__":
    simple_benchmark()
