"""
Shape í…ŒìŠ¤íŠ¸ ì½”ë“œ - flow_matching.pyì™€ ssm.py
"""
import torch
import torch.nn as nn
from flow_matching import RectifiedFlow, RectifiedVectorField, OptimizedTimeEmbedding
from ssm import OptimizedS6Block, OptimizedS6SSMEncoder

def test_flow_matching_shapes():
    """Flow Matching ëª¨ë“ˆë“¤ì˜ shape í…ŒìŠ¤íŠ¸"""
    print("ğŸ§ª Testing Flow Matching Shapes...")
    
    # í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
    batch_size = 4
    dim = 16384
    condition_dim = 768
    hidden_dim = 512
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # 1. OptimizedTimeEmbedding í…ŒìŠ¤íŠ¸
        time_emb = OptimizedTimeEmbedding(hidden_dim).to(device)
        t = torch.rand(batch_size, device=device)
        t_emb = time_emb(t)
        print(f"âœ… TimeEmbedding: {t.shape} -> {t_emb.shape}")
        assert t_emb.shape == (batch_size, hidden_dim // 2), f"Expected {(batch_size, hidden_dim // 2)}, got {t_emb.shape}"
        
        # 2. RectifiedVectorField í…ŒìŠ¤íŠ¸
        vector_field = RectifiedVectorField(dim=dim, condition_dim=condition_dim, hidden_dim=hidden_dim).to(device)
        x = torch.randn(batch_size, dim, device=device)
        condition = torch.randn(batch_size, condition_dim, device=device)
        
        velocity = vector_field(x, t, condition)
        print(f"âœ… VectorField: x{x.shape} + t{t.shape} + c{condition.shape} -> {velocity.shape}")
        assert velocity.shape == (batch_size, dim), f"Expected {(batch_size, dim)}, got {velocity.shape}"
        
        # 3. RectifiedFlow ì „ì²´ í…ŒìŠ¤íŠ¸
        flow = RectifiedFlow(dim=dim, condition_dim=condition_dim, hidden_dim=hidden_dim).to(device)
        
        # ì†ì‹¤ ê³„ì‚° í…ŒìŠ¤íŠ¸
        x1 = torch.randn(batch_size, dim, device=device)
        loss = flow.compute_loss(x1, condition)
        print(f"âœ… Flow Loss: {loss.item():.4f}")
        
        # ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸
        with torch.no_grad():
            samples = flow.sample(condition, num_steps=4)
            print(f"âœ… Flow Sampling: {condition.shape} -> {samples.shape}")
            assert samples.shape == (batch_size, dim), f"Expected {(batch_size, dim)}, got {samples.shape}"
            
        print("âœ… Flow Matching shapes: ALL PASSED")
        
    except Exception as e:
        print(f"âŒ Flow Matching error: {e}")
        import traceback
        traceback.print_exc()

def test_ssm_shapes():
    """SSM ëª¨ë“ˆë“¤ì˜ shape í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Testing SSM Shapes...")
    
    # í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
    batch_size = 4
    seq_len = 100
    d_model = 768
    d_state = 64
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    try:
        # 1. OptimizedS6Block í…ŒìŠ¤íŠ¸
        s6_block = OptimizedS6Block(d_model=d_model, d_state=d_state).to(device)
        x = torch.randn(batch_size, seq_len, d_model, device=device)
        
        output = s6_block(x)
        print(f"âœ… S6Block: {x.shape} -> {output.shape}")
        assert output.shape == (batch_size, seq_len, d_model), f"Expected {(batch_size, seq_len, d_model)}, got {output.shape}"
          # 2. OptimizedS6SSMEncoder í…ŒìŠ¤íŠ¸ - ìµœì í™” ê¸°ëŠ¥ í™œì„±í™”
        encoder = OptimizedS6SSMEncoder(
            d_model=d_model, 
            n_layers=3, 
            d_state=d_state,
            use_fast_layers=True,  # âœ… Fast layers í™œì„±í™”
            use_gradient_checkpointing=True  # âœ… Gradient checkpointing í™œì„±í™”
        ).to(device)
        
        encoded = encoder(x)
        print(f"âœ… S6Encoder: {x.shape} -> {encoded.shape}")
        assert encoded.shape == (batch_size, seq_len, d_model), f"Expected {(batch_size, seq_len, d_model)}, got {encoded.shape}"
        
        print("âœ… SSM shapes: ALL PASSED")
        
    except Exception as e:
        print(f"âŒ SSM error: {e}")
        import traceback
        traceback.print_exc()

def test_memory_usage():
    """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ§ª Testing Memory Usage...")
    
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        initial_memory = torch.cuda.memory_allocated()
          # ì‘ì€ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ - ìµœì í™” ê¸°ëŠ¥ë“¤ í™œì„±í™”
        flow = RectifiedFlow(dim=1024, condition_dim=256, hidden_dim=128).cuda()
        encoder = OptimizedS6SSMEncoder(
            d_model=256, 
            n_layers=2, 
            d_state=32,
            use_fast_layers=True,  # âœ… Fast layers í™œì„±í™”
            use_gradient_checkpointing=True  # âœ… Gradient checkpointing í™œì„±í™”
        ).cuda()
        
        current_memory = torch.cuda.memory_allocated()
        print(f"âœ… Memory usage: {(current_memory - initial_memory) / 1024 / 1024:.2f} MB")
        
        torch.cuda.empty_cache()
    else:
        print("âœ… CPU mode - no GPU memory test")

if __name__ == "__main__":
    print("ğŸš€ Shape Testing Started...")
    
    test_flow_matching_shapes()
    test_ssm_shapes()
    test_memory_usage()
    
    print("\nğŸ‰ All shape tests completed!")
